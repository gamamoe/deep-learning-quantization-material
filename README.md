# Deep Learning Quantization Material
Paper, Course, Video and Article for Deep Learning Quantization

## Paper

- Nagel, Markus, et al. "A white paper on neural network quantization." arXiv preprint arXiv:2106.08295 (2021).
[[Link]](https://arxiv.org/abs/2106.08295)
- Wu, Hao, et al. "Integer quantization for deep learning inference: Principles and empirical evaluation."
arXiv preprint arXiv:2004.09602 (2020). [[Link]](https://arxiv.org/abs/2004.09602)
- Krishnamoorthi, Raghuraman. "Quantizing deep convolutional networks for efficient inference: A whitepaper." 
arXiv preprint arXiv:1806.08342 (2018). [[Link]](https://arxiv.org/abs/1806.08342)
- Jacob, Benoit, et al. "Quantization and training of neural networks for efficient integer-arithmetic-only inference."
Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.
[[Link]](https://openaccess.thecvf.com/content_cvpr_2018/html/Jacob_Quantization_and_Training_CVPR_2018_paper.html)

## Course

- TinyML and Efficient Deep Learning
  - [Fall 23](https://hanlab.mit.edu/courses/2023-fall-65940)
- Hardware for Machine Learning
  - [Spring 24](https://inst.eecs.berkeley.edu/~ee290-2/sp24)
  - [Spring 21](https://inst.eecs.berkeley.edu/~ee290-2/sp21)
- Machine Learning Hardware and Systems
  - [Spring 24](https://abdelfattah-class.github.io/ece5545/sp24)
  - [Spring 23](https://abdelfattah-class.github.io/ece5545/sp23)

## Video

- [tinyML Talks: A Practical Guide to Neural Network Quantization](https://youtu.be/KASuxB3XoYQ)

## Article

- [Achieving FP32 Accuracy for INT8 Inference Using Quantization Aware Training with NVIDIA TensorRT
](https://developer.nvidia.com/blog/achieving-fp32-accuracy-for-int8-inference-using-quantization-aware-training-with-tensorrt/)
